{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from benchmarkrewriter.benchmark_parser import BenchmarkParser, WorkerBenchmarkParser, WorkerEncoding\n",
    "import json\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_path = '/home/dhu/Downloads/benchmarks_with_workers'\n",
    "results_path = '/home/dhu/Downloads/results/'\n",
    "ga_path = '/home/dhu/Downloads/converted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_flexibility(benchmark : WorkerEncoding):\n",
    "    n_assignments = 0\n",
    "    m = benchmark.n_machines()\n",
    "    o = benchmark.n_operations()\n",
    "    durations = benchmark.durations()\n",
    "    w = durations.shape[2]\n",
    "    for i in range(len(durations)):\n",
    "        for j in range(len(durations[i])):\n",
    "            for k in range(len(durations[i][j])):\n",
    "                if durations[i][j][k] > 0:\n",
    "                    n_assignments += 1\n",
    "    average_assignments = n_assignments / o\n",
    "    return average_assignments / n_assignments#(m*w)\n",
    "\n",
    "def get_flexibility_and_dv(benchmark):\n",
    "    all = 0\n",
    "    unique = []\n",
    "    durations = benchmark.durations()\n",
    "    for i in range(len(durations)):\n",
    "        for j in range(len(durations[i])):\n",
    "            if durations[i][j] > 0:\n",
    "                if durations[i][j] not in unique:\n",
    "                    unique.append(durations[i][j])\n",
    "                all += 1.0\n",
    "\n",
    "    return (all / len(durations)) / benchmark.n_machines(), len(unique) / all\n",
    "\n",
    "def get_flexibility_and_dv_worker(benchmark):\n",
    "    all = 0\n",
    "    unique = []\n",
    "    machines_available = 0\n",
    "    durations = benchmark.durations()\n",
    "    for i in range(len(durations)):\n",
    "        for j in range(len(durations[i])):\n",
    "            for k in range(len(durations[i][j])):\n",
    "                if durations[i][j][k] > 0:\n",
    "                    if durations[i][j][k] not in unique:\n",
    "                        unique.append(durations[i][j][k])\n",
    "                    all += 1\n",
    "            if any([x > 0 for x in durations[i][j]]):\n",
    "                machines_available+=1\n",
    "    #return (machines_available / len(durations)) / benchmark.n_machines(), len(unique) / all\n",
    "    return worker_flexibility(benchmark), len(unique) / all\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_benchmarks(path):\n",
    "    sources = os.listdir(path)\n",
    "    result = dict()\n",
    "    for source in sources:\n",
    "        b_path = path + '\\\\' + source + '\\\\'\n",
    "        benchmarks = os.listdir(b_path)\n",
    "        for benchmark in benchmarks:\n",
    "            parser = BenchmarkParser()\n",
    "            #parser = WorkerBenchmarkParser()\n",
    "            data = parser.parse_benchmark(b_path + '\\\\' + benchmark)\n",
    "            f, dv = get_flexibility_and_dv(data)\n",
    "            #f, dv = get_flexibility_and_dv_worker(data)\n",
    "            result[benchmark[:-4]] = {'n_operations': data.n_operations(), 'flexibility': f, 'duration_variety': dv, 'n_machines': data.n_machines()}\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_max(durations):\n",
    "    max = 0\n",
    "    for operation in durations:\n",
    "        for machine in operation:\n",
    "            for worker in machine:\n",
    "                if worker > max:\n",
    "                    max = worker\n",
    "    return max\n",
    "\n",
    "def read_benchmarks_workers(path):\n",
    "    result = dict()\n",
    "    benchmarks = os.listdir(path)\n",
    "    for benchmark in benchmarks:\n",
    "        #parser = BenchmarkParser()\n",
    "        parser = WorkerBenchmarkParser()\n",
    "        data = parser.parse_benchmark(path + '/' + benchmark)\n",
    "        #f, dv = get_flexibility_and_dv(data)\n",
    "        f, dv = get_flexibility_and_dv_worker(data)\n",
    "        instance_name = remap(benchmark[2:-12])\n",
    "        metrics = dict()\n",
    "\n",
    "        max_duration = get_max(data.durations())\n",
    "        counts = [0] * (max_duration+1)\n",
    "        for operation in data.durations():\n",
    "            for machine in operation:\n",
    "                for worker in machine:\n",
    "                    if worker > 0:\n",
    "                        counts[worker] += 1\n",
    "        d_distinct = [x for x in range(len(counts)) if counts[x] > 0]\n",
    "        d_unique = [x for x in range(len(counts)) if counts[x] == 1]\n",
    "        d_shared = [x for x in range(len(counts)) if counts[x] > 1]\n",
    "        metrics['d_distinct'] = d_distinct\n",
    "        metrics['d_unique'] = d_unique\n",
    "        metrics['d_shared'] = d_shared\n",
    "        metrics['d_average'] = sum(counts)/data.n_operations()\n",
    "        result[instance_name] = {'n_operations': data.n_operations(), 'flexibility': f, 'duration_variety': dv, 'n_machines': data.n_machines(), 'additional_metrics': metrics}\n",
    "\n",
    "    return result\n",
    "\n",
    "def remap(name):\n",
    "    if name.startswith('_'):\n",
    "        name = name[1:]\n",
    "    values = name.split('_')\n",
    "    if values[0].startswith('Behnke'):\n",
    "        return 'Behnke'+values[1]\n",
    "    if values[0].startswith('Brandimarte'):\n",
    "        return 'BrandimarteMk'+values[1]\n",
    "    if values[0].startswith('Chambers'):\n",
    "        return 'ChambersBarnes'+values[1]\n",
    "    if values[0].startswith('HurinkS'):\n",
    "        return 'HurinkSdata'+values[1]\n",
    "    if values[0].startswith('HurinkE'):\n",
    "        return 'HurinkEdata'+values[1]\n",
    "    if values[0].startswith('HurinkR'):\n",
    "        return 'HurinkRdata'+values[1]\n",
    "    if values[0].startswith('HurinkV'):\n",
    "        return 'HurinkVdata'+values[1]\n",
    "    if values[0].startswith('DP'):\n",
    "        return 'DPpaulli'+values[1]\n",
    "    if values[0].startswith('Kacem'):\n",
    "        return 'Kacem'+values[1]\n",
    "    if values[0].startswith('Fattahi'):\n",
    "        return 'Fattahi'+values[1]\n",
    "    return name\n",
    "\n",
    "def read_results(path):\n",
    "    files = os.listdir(path)\n",
    "    #files = [path_to_results + r'results_ortools.txt', path_to_results +r'results_cplex_cp.txt', path_to_results +r'results_gurobi.txt', path_to_results +r'results_hexaly_rewritten.txt', path_to_results +r'results_cplex_lp_rewritten.txt']\n",
    "    all_data = dict()\n",
    "    data_as_dict = dict()\n",
    "    known_optima = dict()\n",
    "    for file in files:\n",
    "        statuses = []\n",
    "        optimal = 0\n",
    "        feasible = 0\n",
    "        infeasible = 0\n",
    "        file_content = pd.read_csv(path + file, names=['name','optimization_status','fitness_value','lower_bound', 'runtime', 'result_vector1', 'result_vector2', 'result_vector3', 'peak_cpu', 'peak_ram', 'resource_history', 'best_result_history'], sep=';')#, converters={'best_result_history': pd.eval})\n",
    "        df = pd.DataFrame(file_content)\n",
    "        name = file.split('\\\\')[-1][8:-4]\n",
    "        if name == 'hexaly_rewritten':\n",
    "            name = 'hexaly'#all_data['results_hexaly'] = df\n",
    "        elif name == 'cplex_lp_rewritten':\n",
    "            name = 'cplex_lp'#all_data['results_cplex_lp'] = df\n",
    "        all_data[name] = df\n",
    "        for index, row in df.iterrows():\n",
    "            if row['name'].startswith('Error'):\n",
    "                infeasible += 1\n",
    "                continue\n",
    "            if name not in data_as_dict:\n",
    "                data_as_dict[name] = dict()\n",
    "            instance_name = remap(row['name'][2:-12])\n",
    "            if name == 'hexaly' or not row['optimization_status'] < 0:\n",
    "                data_as_dict[name][instance_name] = row['fitness_value']\n",
    "                if row['optimization_status'] == 1.0:\n",
    "                    found = False\n",
    "                    for optima in known_optima:\n",
    "                        if optima[0] == instance_name:\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        known_optima[instance_name] = row['fitness_value']#.append((instance_name, row['fitness_value']))\n",
    "                    optimal += 1\n",
    "                else:\n",
    "                    feasible += 1\n",
    "            else:\n",
    "                infeasible += 1\n",
    "            if row['optimization_status'] not in statuses:\n",
    "                statuses.append(row['optimization_status'])\n",
    "        print(f'{name}: {statuses} - optimal: {optimal}, feasible: {feasible}, infeasible: {infeasible}')\n",
    "    return data_as_dict, known_optima\n",
    "\n",
    "def read_ga_results(path):\n",
    "    results = dict()\n",
    "    files = os.listdir(path)\n",
    "    results['ga_best'] = dict()\n",
    "    results['ga_average'] = dict()\n",
    "    for file in files:\n",
    "        if file == 'converted':\n",
    "            continue\n",
    "        with open(path + file, 'r') as f:\n",
    "            ga_data = json.loads(f.read())\n",
    "\n",
    "            \n",
    "            for key in ga_data.keys():\n",
    "                results['ga_best'][remap(key)] = ga_data[key]['best']\n",
    "                results['ga_average'][remap(key)] = ga_data[key]['average']\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurobi: [0.0, -1.0, 1.0] - optimal: 15, feasible: 305, infeasible: 70\n",
      "cplex_lp: [1.0, 0.0, -1.0] - optimal: 12, feasible: 309, infeasible: 81\n",
      "hexaly: [-1] - optimal: 0, feasible: 402, infeasible: 0\n",
      "hexaly: [-1, 1] - optimal: 29, feasible: 373, infeasible: 0\n",
      "cplex_cp: [0.0, 1.0] - optimal: 55, feasible: 345, infeasible: 2\n",
      "ortools: [0.0, 1.0] - optimal: 39, feasible: 358, infeasible: 5\n",
      "cplex_lp: [0.0, -1.0] - optimal: 0, feasible: 321, infeasible: 81\n"
     ]
    }
   ],
   "source": [
    "results_data, known_optima = read_results(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ga_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_ga_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mga_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m ga_data:\n\u001b[1;32m      3\u001b[0m     results_data[key] \u001b[38;5;241m=\u001b[39m ga_data[key]\n",
      "Cell \u001b[0;32mIn[4], line 140\u001b[0m, in \u001b[0;36mread_ga_results\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m+\u001b[39m file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    137\u001b[0m     ga_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mga_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m():\n\u001b[1;32m    141\u001b[0m         results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mga_best\u001b[39m\u001b[38;5;124m'\u001b[39m][remap(key)] \u001b[38;5;241m=\u001b[39m ga_data[key][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    142\u001b[0m         results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mga_average\u001b[39m\u001b[38;5;124m'\u001b[39m][remap(key)] \u001b[38;5;241m=\u001b[39m ga_data[key][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "ga_data = read_ga_results(ga_path)\n",
    "for key in ga_data:\n",
    "    results_data[key] = ga_data[key]\n",
    "    optimal = 0\n",
    "    feasible = 0\n",
    "    infeasible = 0 # will stay 0, obviously\n",
    "    for instance in ga_data[key]:\n",
    "        if instance in known_optima and ga_data[key][instance] == known_optima[instance]:\n",
    "            optimal += 1\n",
    "        else:\n",
    "            feasible += 1\n",
    "#print(f'{key}:[0.0, 1.0] - optimal: {optimal}, feasible: {feasible}, infeasible: {infeasible}')\n",
    "print(len(known_optima))\n",
    "print(known_optima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_data = read_benchmarks_workers(benchmark_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
